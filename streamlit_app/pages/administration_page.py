import streamlit as st
import requests
import json

st.set_page_config(page_title="Administration - ATLAS", page_icon="‚öôÔ∏è", layout="wide")

st.title("‚öôÔ∏è Administration - Scraping √† la demande")

st.markdown("---")

# ============================================================================
# CONFIGURATION
# ============================================================================

API_BASE_URL = "http://localhost:8000"


# ============================================================================
# FONCTIONS
# ============================================================================


def scrape_offer(source: str, identifier: str, save_to_db: bool = False) -> dict:
    """
    Appeler l'API de scraping

    Args:
        source: "wttj" ou "france_travail"
        identifier: URL pour WTTJ, ID pour France Travail
        save_to_db: Sauvegarder en BDD apr√®s scraping

    Returns:
        R√©ponse JSON de l'API
    """
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/scrape",
            json={"source": source, "identifier": identifier, "save_to_db": save_to_db},
            timeout=300,
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Erreur lors de l'appel API: {str(e)}")
        return None
    except Exception as e:
        st.error(f"‚ùå Erreur: {str(e)}")
        return None


def display_raw_data(raw_data: dict):
    """Afficher les donn√©es brutes scrap√©es"""
    st.subheader("üì¶ Donn√©es brutes")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**Titre**")
        st.write(raw_data.get("title", "N/A"))

        st.markdown("**Entreprise**")
        st.write(raw_data.get("company_name", "N/A"))

        st.markdown("**Type de contrat**")
        st.write(raw_data.get("contract_type", "N/A"))

        st.markdown("**Localisation**")
        location = raw_data.get("location_city", "N/A")
        if raw_data.get("location_code_postal"):
            location += f" ({raw_data.get('location_code_postal')})"
        st.write(location)

    with col2:
        st.markdown("**Date de publication**")
        st.write(raw_data.get("published_date", "N/A"))

        st.markdown("**Source**")
        st.write(raw_data.get("source", "N/A"))

        st.markdown("**URL**")
        st.write(raw_data.get("url", "N/A"))

        if raw_data.get("salary_text"):
            st.markdown("**Salaire**")
            st.write(raw_data.get("salary_text"))

    # Description compl√®te
    st.markdown("**Description**")
    description = raw_data.get("description", "N/A")
    if description and description != "N/A":
        with st.expander(
            f"Voir la description ({len(description)} caract√®res)", expanded=False
        ):
            st.text_area(
                "Description compl√®te",
                description,
                height=300,
                disabled=True,
                label_visibility="collapsed",
            )
    else:
        st.write("Pas de description disponible")


def display_nlp_results(nlp_results: dict):
    """Afficher les r√©sultats du traitement NLP"""
    st.subheader("üß† R√©sultats du traitement NLP")

    if "error" in nlp_results:
        st.error(f"‚ùå Erreur NLP: {nlp_results['error']}")
        return

    # R√©sum√© final
    if "final" in nlp_results:
        st.markdown("### üìä R√©sum√©")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "Profil d√©tect√©", nlp_results["final"].get("profile_category", "N/A")
            )
            confidence = nlp_results["final"].get("profile_confidence", 0)
            st.caption(
                f"Confiance: {confidence:.1%}" if confidence else "Confiance: N/A"
            )

        with col2:
            st.metric(
                "Comp√©tences extraites", nlp_results["final"].get("skills_count", 0)
            )

        with col3:
            st.metric(
                "Dimensions embedding",
                nlp_results["final"].get("embedding_dimensions", 0),
            )

        # D√©tails suppl√©mentaires
        st.markdown("---")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Type de contrat**")
            contract_types = nlp_results["final"].get("contract_types", [])
            st.write(", ".join(contract_types) if contract_types else "N/A")

            st.markdown("**Niveau d'√©tudes**")
            edu_level = nlp_results["final"].get("education_level")
            st.write(f"Niveau {edu_level}" if edu_level else "N/A")

        with col2:
            st.markdown("**Type de formation**")
            st.write(nlp_results["final"].get("education_type", "N/A"))

        with col3:
            st.markdown("**T√©l√©travail**")
            remote = nlp_results["final"].get("remote_possible", False)
            if remote:
                days = nlp_results["final"].get("remote_days")
                percentage = nlp_results["final"].get("remote_percentage")
                remote_text = "Oui"
                if days:
                    remote_text += f" ({days} jours/semaine)"
                elif percentage:
                    remote_text += f" ({percentage}%)"
                st.write(remote_text)
            else:
                st.write("Non")

    # Top comp√©tences
    if "final" in nlp_results and nlp_results["final"].get("top_skills"):
        st.markdown("### üéØ Top 10 des comp√©tences")
        skills = nlp_results["final"]["top_skills"]

        # Afficher en colonnes
        cols = st.columns(5)
        for i, skill in enumerate(skills):
            with cols[i % 5]:
                st.markdown(f"‚Ä¢ {skill}")

    # D√©tails des √©tapes NLP
    if "steps" in nlp_results:
        st.markdown("---")
        st.markdown("### üî¨ D√©tails du traitement")

        # 1. Texte nettoy√©
        if "cleaned_text" in nlp_results["steps"]:
            with st.expander("1Ô∏è‚É£ Texte nettoy√© et lemmatis√©", expanded=False):
                cleaned = nlp_results["steps"]["cleaned_text"]
                st.text_area(
                    "Texte apr√®s nettoyage",
                    cleaned,
                    height=200,
                    disabled=True,
                    label_visibility="collapsed",
                )
                st.caption(f"Longueur: {len(cleaned)} caract√®res")

        # 2. Extraction d'informations
        if "info_extraction" in nlp_results["steps"]:
            with st.expander("2Ô∏è‚É£ Informations extraites", expanded=False):
                info = nlp_results["steps"]["info_extraction"]
                st.json(info)

        # 3. Comp√©tences compl√®tes
        if "skills_extracted" in nlp_results["steps"]:
            with st.expander("3Ô∏è‚É£ Toutes les comp√©tences extraites", expanded=False):
                skills_dict = nlp_results["steps"]["skills_extracted"]

                # V√©rifier si c'est un dictionnaire avec cat√©gories
                if isinstance(skills_dict, dict):
                    # Compter le total
                    total_skills = sum(
                        len(v) for v in skills_dict.values() if isinstance(v, list)
                    )
                    st.write(f"**{total_skills} comp√©tences d√©tect√©es:**")

                    # Afficher par cat√©gorie
                    for category, skill_list in skills_dict.items():
                        if isinstance(skill_list, list) and skill_list:
                            st.markdown(
                                f"**{category.capitalize()}** ({len(skill_list)}):"
                            )
                            cols = st.columns(4)
                            for i, skill in enumerate(skill_list):
                                with cols[i % 4]:
                                    st.markdown(f"‚Ä¢ {skill}")
                            st.markdown("")  # Espace entre cat√©gories
                else:
                    # Format liste simple (fallback)
                    st.write(f"**{len(skills_dict)} comp√©tences d√©tect√©es:**")
                    if skills_dict:
                        cols = st.columns(4)
                        for i, skill in enumerate(skills_dict):
                            with cols[i % 4]:
                                st.markdown(f"‚Ä¢ {skill}")
                    else:
                        st.write("Aucune comp√©tence d√©tect√©e")

        # 4. Embedding
        if "embedding" in nlp_results["steps"]:
            with st.expander("4Ô∏è‚É£ Embedding vectoriel", expanded=False):
                emb_info = nlp_results["steps"]["embedding"]

                st.markdown(f"**Mod√®le:** {emb_info.get('model', 'N/A')}")
                st.markdown(f"**Dimensions:** {emb_info.get('shape', 'N/A')}")

                if "vector" in emb_info:
                    st.markdown("**Vecteur (premiers 20 √©l√©ments):**")
                    vector = emb_info["vector"]
                    st.code(str(vector[:20]))

                    st.caption(f"Vecteur complet: {len(vector)} dimensions")


# ============================================================================
# INTERFACE
# ============================================================================

st.markdown(
    """
Cette page permet de scraper et analyser une offre d'emploi √† la demande.

**Sources disponibles:**
- **Welcome to the Jungle (WTTJ):** Entrez l'URL compl√®te de l'offre
- **France Travail:** Entrez l'ID de l'offre (visible dans l'URL)
"""
)

st.markdown("---")

# S√©lection de la source
col1, col2 = st.columns([1, 2])

with col1:
    source = st.selectbox(
        "üìå Source",
        options=["wttj", "france_travail"],
        format_func=lambda x: (
            "Welcome to the Jungle" if x == "wttj" else "France Travail"
        ),
        help="S√©lectionnez la source de l'offre √† scraper",
    )

with col2:
    if source == "wttj":
        identifier = st.text_input(
            "üîó URL de l'offre WTTJ",
            placeholder="https://www.welcometothejungle.com/fr/companies/...",
            help="Copiez-collez l'URL compl√®te de l'offre Welcome to the Jungle",
        )
    else:  # france_travail
        identifier = st.text_input(
            "üî¢ ID de l'offre France Travail",
            placeholder="Ex: 180MVNK",
            help="Entrez l'ID de l'offre (visible dans l'URL candidat.francetravail.fr/offres/recherche/detail/ID)",
        )

# Option de sauvegarde en BDD
save_to_db = st.checkbox(
    "üíæ Sauvegarder l'offre en base de donn√©es apr√®s traitement",
    value=False,
    help="L'offre sera ins√©r√©e/mise √† jour dans PostgreSQL avec tous les r√©sultats NLP",
)

# Bouton de scraping
if st.button("üöÄ Scraper et analyser", type="primary", use_container_width=True):
    if not identifier:
        st.warning("‚ö†Ô∏è Veuillez entrer un identifiant d'offre")
    else:
        with st.spinner("üîÑ Scraping et traitement NLP en cours..."):
            result = scrape_offer(source, identifier, save_to_db)

        if result and result.get("success"):
            st.success("‚úÖ Scraping et analyse termin√©s avec succ√®s!")

            # Confirmation sauvegarde BDD
            if result.get("saved_to_db"):
                st.success("üíæ Offre sauvegard√©e en base de donn√©es!")
            elif save_to_db:
                st.warning("‚ö†Ô∏è Sauvegarde en BDD √©chou√©e (voir logs API)")

            st.markdown("---")

            # Affichage des donn√©es brutes
            if "raw_data" in result:
                display_raw_data(result["raw_data"])

            st.markdown("---")

            # Affichage des r√©sultats NLP
            if "nlp_results" in result:
                display_nlp_results(result["nlp_results"])
        else:
            st.error("‚ùå √âchec du scraping. V√©rifiez l'identifiant et r√©essayez.")
