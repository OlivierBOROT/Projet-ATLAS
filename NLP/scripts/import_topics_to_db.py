"""
import_topics_to_db.py (CORRIG√â)

Importe les topics du CSV g√©n√©r√© vers la base de donn√©es PostgreSQL
"""

import os
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv
from datetime import datetime

print("="*80)
print("üì• IMPORT TOPICS VERS BASE DE DONN√âES")
print("="*80)
print()

# ============================================================================
# CONFIGURATION
# ============================================================================

load_dotenv()
DATABASE_URL = os.getenv('DATABASE_URL')

# Fichier CSV g√©n√©r√© par topic modeling
CSV_FILE = "topic_modeling_results_20251230_134751.csv"

# ============================================================================
# CHARGEMENT DONN√âES
# ============================================================================

print("üìä Chargement du CSV...")

try:
    df = pd.read_csv(CSV_FILE, encoding='utf-8')
    print(f"   ‚úÖ {len(df):,} lignes charg√©es")
    print(f"\n   Colonnes : {list(df.columns)}")
    
except FileNotFoundError:
    print(f"   ‚ùå ERREUR : Fichier {CSV_FILE} introuvable")
    print("\n   üí° Fichiers CSV disponibles :")
    import glob
    for f in glob.glob("topic_modeling_results_*.csv"):
        print(f"      - {f}")
    exit(1)

# V√©rifier structure - ADAPTER AUX NOMS DES COLONNES
if 'dominant_topic' in df.columns:
    # Renommer pour compatibilit√©
    df['topic_id'] = df['dominant_topic']
    print("   ‚úÖ Colonne 'dominant_topic' renomm√©e en 'topic_id'")
elif 'topic_id' not in df.columns:
    print(f"\n   ‚ùå ERREUR : Ni 'topic_id' ni 'dominant_topic' trouv√©")
    print(f"   Colonnes disponibles : {list(df.columns)}")
    exit(1)

# V√©rifier autres colonnes requises
required_cols = ['offer_id', 'topic_id', 'topic_label', 'topic_confidence']
missing = [col for col in required_cols if col not in df.columns]

if missing:
    print(f"\n   ‚ùå ERREUR : Colonnes manquantes : {missing}")
    exit(1)

print(f"\n   ‚úÖ Structure valid√©e")

# Afficher aper√ßu
print(f"\n   Aper√ßu des donn√©es :")
print(df[['offer_id', 'topic_id', 'topic_label', 'topic_confidence']].head(3))

# ============================================================================
# CONNEXION BDD
# ============================================================================

print("\nüîå Connexion √† la base de donn√©es...")

try:
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    print("   ‚úÖ Connect√©")
    
except Exception as e:
    print(f"   ‚ùå ERREUR : {e}")
    exit(1)

# ============================================================================
# V√âRIFIER SI COLONNES EXISTENT
# ============================================================================

print("\nüîç V√©rification structure BDD...")

cur.execute("""
    SELECT column_name 
    FROM information_schema.columns 
    WHERE table_name = 'fact_job_offers' 
    AND column_name IN ('topic_id', 'topic_label', 'topic_confidence')
""")

existing_cols = [row[0] for row in cur.fetchall()]

if len(existing_cols) < 3:
    print(f"   ‚ö†Ô∏è  Colonnes manquantes : {set(['topic_id', 'topic_label', 'topic_confidence']) - set(existing_cols)}")
    print(f"   üí° Ex√©cuter d'abord : add_topics_to_db.sql")
    
    response = input("\n   Voulez-vous que je les cr√©e maintenant ? (y/n) : ")
    if response.lower() == 'y':
        print("\n   üîß Cr√©ation des colonnes...")
        try:
            cur.execute("""
                ALTER TABLE fact_job_offers
                ADD COLUMN IF NOT EXISTS topic_id INTEGER,
                ADD COLUMN IF NOT EXISTS topic_label VARCHAR(100),
                ADD COLUMN IF NOT EXISTS topic_confidence DECIMAL(3,2)
            """)
            conn.commit()
            print("   ‚úÖ Colonnes cr√©√©es")
        except Exception as e:
            print(f"   ‚ùå ERREUR : {e}")
            exit(1)
    else:
        exit(0)
else:
    print(f"   ‚úÖ Colonnes existantes : {existing_cols}")

# ============================================================================
# IMPORT TOPICS
# ============================================================================

print("\nüì• Import des topics dans fact_job_offers...")

# Pr√©parer donn√©es
updates = []
for _, row in df.iterrows():
    updates.append((
        int(row['topic_id']),
        str(row['topic_label']),
        float(row['topic_confidence']),
        int(row['offer_id'])
    ))

print(f"   ‚è≥ Mise √† jour de {len(updates):,} offres...")

# Update par batch (plus rapide)
update_query = """
    UPDATE fact_job_offers
    SET 
        topic_id = data.topic_id,
        topic_label = data.topic_label,
        topic_confidence = data.topic_confidence
    FROM (VALUES %s) AS data(topic_id, topic_label, topic_confidence, offer_id)
    WHERE fact_job_offers.offer_id = data.offer_id
"""

try:
    execute_values(
        cur,
        update_query,
        updates,
        template="(%s, %s, %s, %s)"
    )
    
    conn.commit()
    
    # V√©rifier r√©sultat
    cur.execute("SELECT COUNT(*) FROM fact_job_offers WHERE topic_id IS NOT NULL")
    count = cur.fetchone()[0]
    
    print(f"   ‚úÖ {count:,} offres mises √† jour avec succ√®s")
    
except Exception as e:
    conn.rollback()
    print(f"   ‚ùå ERREUR lors de l'import : {e}")
    cur.close()
    conn.close()
    exit(1)

# ============================================================================
# STATISTIQUES
# ============================================================================

print("\nüìä Statistiques post-import...")

# Distribution des topics
cur.execute("""
    SELECT 
        topic_id,
        topic_label,
        COUNT(*) as nb_offres,
        ROUND(AVG(topic_confidence)::numeric, 2) as confiance_moy
    FROM fact_job_offers
    WHERE topic_id IS NOT NULL
    GROUP BY topic_id, topic_label
    ORDER BY topic_id
""")

print("\n   Distribution des topics :")
total = 0
for row in cur.fetchall():
    topic_id, label, count, conf = row
    pct = (count / len(df)) * 100
    print(f"   Topic {topic_id} : {label:50} ‚Üí {count:5} offres ({pct:5.1f}%) | conf={conf}")
    total += count

print(f"\n   TOTAL : {total:,} offres avec topics")

# Topics par r√©gion (Top 5)
cur.execute("""
    SELECT 
        r.nom_region,
        COUNT(*) as nb_offres
    FROM fact_job_offers f
    JOIN ref_communes_france r ON f.commune_id = r.commune_id
    WHERE f.topic_id IS NOT NULL
    GROUP BY r.nom_region
    ORDER BY nb_offres DESC
    LIMIT 5
""")

print("\n   Top 5 r√©gions avec topics :")
for row in cur.fetchall():
    region, count = row
    print(f"   {region:30} : {count:4} offres")

# Confiance moyenne par topic
cur.execute("""
    SELECT 
        topic_label,
        COUNT(*) as nb_offres,
        ROUND(AVG(topic_confidence)::numeric, 3) as conf_moy,
        ROUND(MIN(topic_confidence)::numeric, 3) as conf_min,
        ROUND(MAX(topic_confidence)::numeric, 3) as conf_max
    FROM fact_job_offers
    WHERE topic_id IS NOT NULL
    GROUP BY topic_label
    ORDER BY nb_offres DESC
""")

print("\n   Qualit√© des pr√©dictions (confiance) :")
for row in cur.fetchall():
    label, count, avg_conf, min_conf, max_conf = row
    print(f"   {label[:40]:40} | avg={avg_conf} min={min_conf} max={max_conf}")

# ============================================================================
# FINALISATION
# ============================================================================

cur.close()
conn.close()

print("\n" + "="*80)
print("‚úÖ IMPORT TERMIN√â AVEC SUCC√àS")
print("="*80)
print(f"""
üìä R√©sum√© :
   - {len(df):,} topics import√©s depuis CSV
   - Base de donn√©es mise √† jour
   - Colonnes ajout√©es : topic_id, topic_label, topic_confidence
   
üéØ Prochaines √©tapes :
   1. Cr√©er table dim_topics (optionnel) : add_topics_to_db.sql
   2. Enrichissement NLP complet : nlp_enrichment_full.py
   3. Visualisations Streamlit
   
üí° Test rapide :
   SELECT topic_label, COUNT(*) 
   FROM fact_job_offers 
   WHERE topic_id IS NOT NULL 
   GROUP BY topic_label;
""")